{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5782c303244c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import MINST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# import MINST dataset\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18fa04df160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18fa0510ef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create plots in same page\n",
    "%matplotlib inline \n",
    "\n",
    "#  select a random number to display\n",
    "# we can select anything up to 60,000 as the trainig data has 60,000 images\n",
    "image_index = 7077 \n",
    "\n",
    "print(y_train[image_index]) \n",
    "\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the CNN, we need to know the shape of the training dataset. \n",
    "\n",
    "The output: (60000, 28, 28) revelas two details about the dataset.\n",
    "1. The number of image in the training set : which is 60,000\n",
    "2. The size of the image in pixels (28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going throguh the dataset, the below implementation will create a CNN for model building. \n",
    "\n",
    "In a image classification problem, it is considered that the dependency between two pixels are only related with the adjacent and close pixels. Therefore a technique like CNN is suitable for image classification where it's convolution allows the model to preserve the relationship between different parts of an image.\n",
    "\n",
    "\n",
    "In the convolution layer which is the first layer of the model, the features of the image is extracted. In that layer the pixels are processed using a pixel filer that decreases the size of the image without loosing the relationship between pixels.\n",
    "\n",
    "\n",
    "The feature map, which is the output of an image and the filter tells where the features are in the image. The higher the value, the more the corresponding place in the image resembles the feature. The dynamic nature of the model leraning as the features are not pre-defined according to a particular formalism, but learned by the network during the training phase was a high point in choosing the CNN for this criteria. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Keras is looing for a 4-dims numpy arrays, the shape of the dataset is reshaped to match the requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3467bd0214ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reshaping the array to 4-dims so that it can work with the Keras API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training and testing dataset \n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]: MINST data catelog; https://www.tensorflow.org/datasets/catalog/mnist\n",
    "\n",
    "[2]: THE MNIST DATABASE of handwritten digits; Yann LeCun, Corinna Cortes, Christopher J.C. Burges; http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "\n",
    "[3]: Understand the architecture of CNN; https://towardsdatascience.com/understand-the-architecture-of-cnn-90a25e244c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
