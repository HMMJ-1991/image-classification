{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iZc2Fpd9VuaD",
    "outputId": "0a08c52f-94f1-4dbb-8847-0b0b475cc2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import MINST dataset\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "0zUilSZmVuaO",
    "outputId": "6112bea0-2a83-4488-d8bd-a825ce32cfb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe32c3f82b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create plots in same page\n",
    "%matplotlib inline \n",
    "\n",
    "#  select a random number to display\n",
    "# we can select anything up to 60,000 as the trainig data has 60,000 images\n",
    "image_index = 7077 \n",
    "\n",
    "print(y_train[image_index]) \n",
    "\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ibb8a5wAVuaY"
   },
   "source": [
    "In order to train the CNN, we need to know the shape of the training dataset. \n",
    "\n",
    "The output: (60000, 28, 28) revelas two details about the dataset.\n",
    "1. The number of image in the training set : which is 60,000\n",
    "2. The size of the image in pixels (28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djoub6hoVuaa",
    "outputId": "22fe8520-1f85-43d0-bd6a-1d6ff13167ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kixqJ5U2WZWx"
   },
   "source": [
    "After going throguh the dataset, the below implementation will create a CNN for model building.\n",
    "\n",
    "In a image classification problem, it is considered that the dependency between two pixels are only related with the adjacent and close pixels. Therefore a technique like CNN is suitable for image classification where it's convolution allows the model to preserve the relationship between different parts of an image.\n",
    "\n",
    "In the convolution layer which is the first layer of the model, the features of the image is extracted. In that layer the pixels are processed using a pixel filer that decreases the size of the image without loosing the relationship between pixels.\n",
    "\n",
    "The feature map, which is the output of an image and the filter tells where the features are in the image. The higher the value, the more the corresponding place in the image resembles the feature. The dynamic nature of the model leraning as the features are not pre-defined according to a particular formalism, but learned by the network during the training phase was a high point in choosing the CNN for this criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0j19MA6WfDQ"
   },
   "source": [
    "As the Keras is looing for a 4-dims numpy arrays, the shape of the dataset is reshaped to match the requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBBuYJCnVuai"
   },
   "outputs": [],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYMKyKjhr5sz"
   },
   "source": [
    "Normalise the training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PLl8nsUWqwD"
   },
   "outputs": [],
   "source": [
    "# Normalize the training and testing dataset \n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model development, I have used Keras sequential model and added Conv2D, MaxPooling, Flatten, Dropout and Dense layers. \n",
    "\n",
    "The dropout layers helps reducing the model overfitting disregarding some of the neurons and the Flatten layers flatten 2D arrays to 1D array before building the fully connected layers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IrjwHxiQW73g"
   },
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "eHXG5chKXBx9",
    "outputId": "80c53a51-4aa0-4fea-83cf-45b72e39e36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.2350 - accuracy: 0.9302\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.1011 - accuracy: 0.9691\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0710 - accuracy: 0.9775\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0534 - accuracy: 0.9829\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0418 - accuracy: 0.9858\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0333 - accuracy: 0.9889\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0266 - accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0229 - accuracy: 0.9927\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0205 - accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0183 - accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe325910cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dvho4EILhlUs"
   },
   "source": [
    "Epoch 1/10\n",
    "1875/1875 [==============================] - 31s 17ms/step - loss: 0.2350 - accuracy: 0.9302\n",
    "\n",
    "Epoch 2/10\n",
    "1875/1875 [==============================] - 31s 17ms/step - loss: 0.1011 - accuracy: 0.9691\n",
    "\n",
    "Epoch 3/10\n",
    "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0710 - accuracy: 0.9775\n",
    "\n",
    "Epoch 4/10\n",
    "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0534 - accuracy: 0.9829\n",
    "\n",
    "Epoch 5/10\n",
    "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0418 - accuracy: 0.9858\n",
    "\n",
    "Epoch 6/10\n",
    "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0333 - accuracy: 0.9889\n",
    "\n",
    "Epoch 7/10\n",
    "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0266 - accuracy: 0.9908\n",
    "\n",
    "Epoch 8/10\n",
    "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0229 - accuracy: 0.9927\n",
    "\n",
    "Epoch 9/10\n",
    "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0205 - accuracy: 0.9931\n",
    "\n",
    "Epoch 10/10\n",
    "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0183 - accuracy: 0.9938\n",
    "<tensorflow.python.keras.callbacks.History at 0x7fe325910cc0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "h95QWrM5XDXj",
    "outputId": "8f3beedc-2a79-4317-f83d-05ab704eb943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0644 - accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06436172127723694, 0.9829999804496765]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "tF3KGLV_XTTv",
    "outputId": "d897b012-df22-4b61-afba-ef55826560ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7TIj8hpWSkQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAzb83hgVuap"
   },
   "source": [
    "Resources:\n",
    "\n",
    "\n",
    "[1]: MINST data catelog; https://www.tensorflow.org/datasets/catalog/mnist\n",
    "\n",
    "[2]: THE MNIST DATABASE of handwritten digits; Yann LeCun, Corinna Cortes, Christopher J.C. Burges; http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "[3]: Understand the architecture of CNN; https://towardsdatascience.com/understand-the-architecture-of-cnn-90a25e244c7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ww3mzIDNVuar"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Answer_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
